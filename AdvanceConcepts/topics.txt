Advance concepts and topics

Getters and setters
    Refer getters_setters.py

GIL (Global Interpreter Lock)
    Global Interpreter Lock (GIL) ensures that only one thread executes Python bytecode at a time.
    the GIL (Global Interpreter Lock) handles thread safety at the bytecode level, 
    it doesn't guarantee thread-safety at the object instantiation level when 
    multiple threads are concurrently checking cls._instance. 
    This can lead to race conditions where multiple instances are created.

__new__ vs. __init__
    The __new__ method is responsible for actually creating the instance of the class.
    The __init__ method is the initializer, called after an object has already been created.

Process
    A process is a self-contained unit of execution with its own memory space, resources, and execution context.

Thread
    A thread is the smallest unit of execution within a process. 
    Threads share the same memory space as other threads in the same process but have their own execution stack.
    Multiple threads within the same process can run concurrently.

Concurrency
    The ability to manage multiple tasks at once (not necessarily at the same time).
    Broader concept — can include threading, multiprocessing, etc.

Parallelism
    Parallelism refers to performing tasks simultaneously.
    Tasks may share memory or be independent (depending on the implementation, e.g., multithreading vs. multiprocessing).

Multithreading
    A specific implementation of concurrency where tasks are divided into threads that run in parallel or overlap.
    multithreading is often used to achieve concurrency, 
    It can also lead to parallelism when running on a multi-core processor.
    Even though the threads are running on different cores, they still share memory, which means they are part of the same process.
    In Python, we cannot achieve true parallelism for CPU-bound tasks using multithreading even if it has multiple cores due to GIL.
    But in other languages we can as each thread runs simultaneously on its own core, achieving parallelism.

Multiprocessing
    Multiprocessing is a specific technique for achieving parallelism by using multiple processes.
    Processes have separate memory spaces, so they do not share memory.

How Cores Are Utilized by Threads and Processes:
    Multicore:

    1. When Running a Process:
    A core can run one process at a time. 
    For example, if you have a 4-core CPU, you could run 4 separate processes at the same time, each assigned to one core.

    2. When Running Threads:
    Threads are part of a process.
    A core can run multiple threads from the same or different processes simultaneously if the CPU has multiple cores.
    If a process has 4 threads, and there are 4 cores, each thread can run on a different core, enabling true parallelism


    Single core:
    1. When Running a Process:
    A single-core CPU, if you're running multiple processes, they will also take turns executing on that single core (through time-slicing).
    However, processes are isolated, so they don't share memory directly, unlike threads.


    2. When Running Threads:
    A single core can run multiple threads (from the same process or different processes), but they must share the core’s resources. 
    The operating system schedules these threads to run, possibly switching between them very quickly (time-slicing).

a single-core CPU, if you're running multiple processes, they will also take turns executing on that single core (through time-slicing). However, processes are isolated, so they don't share memory directly, unlike threads.
Subroutines 
    Nothing but functions. Typically runs sequentially, blocking other operations while running. Ex: sum()

Coroutines
    These run concurrently, Can pause and resume execution, asynchronous behaviour. Ex: I/O operation.